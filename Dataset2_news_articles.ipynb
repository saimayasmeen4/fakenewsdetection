{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset2_news_articles.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y69a2GSsFHVd",
        "outputId": "3a262a7f-a4b5-4c0f-e074-3ce035e2e871"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTIorOriJ_FE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731e989a-9a4d-4e0d-8f99-715295a42a51"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk \n",
        "import re\n",
        "from pandas_profiling import ProfileReport\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import sklearn.metrics\n",
        "import sklearn\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRwB8g_kKK2p"
      },
      "source": [
        "Read news aricle csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2uVhaz0J0zb",
        "outputId": "97bb93b6-a484-41b5-ddbc-02056ff21c69"
      },
      "source": [
        "data = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/ML Freelance/news_articles.csv', encoding=\"latin\", index_col=0)\n",
        "data = data.dropna()\n",
        "data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "published                  2045\n",
              "title                      2045\n",
              "text                       2045\n",
              "language                   2045\n",
              "site_url                   2045\n",
              "main_img_url               2045\n",
              "type                       2045\n",
              "label                      2045\n",
              "title_without_stopwords    2045\n",
              "text_without_stopwords     2045\n",
              "hasImage                   2045\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QHZr6iHKXdf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C21HUwJUduZ4"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX8O9Yuudvhp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c5d67873-c475-4ce5-dc94-d25aa7937b3d"
      },
      "source": [
        "data.groupby('label').describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">hasImage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fake</th>\n",
              "      <td>1291.0</td>\n",
              "      <td>0.736638</td>\n",
              "      <td>0.440628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Real</th>\n",
              "      <td>754.0</td>\n",
              "      <td>0.834218</td>\n",
              "      <td>0.372132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      hasImage                                             \n",
              "         count      mean       std  min  25%  50%  75%  max\n",
              "label                                                      \n",
              "Fake    1291.0  0.736638  0.440628  0.0  0.0  1.0  1.0  1.0\n",
              "Real     754.0  0.834218  0.372132  0.0  1.0  1.0  1.0  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOEAcOYd280"
      },
      "source": [
        "data=data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I1uyV2zwcjV"
      },
      "source": [
        "# Seperating Independent and dependent features\n",
        "X = data.drop(columns=['label'],axis=1)\n",
        "y = data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EU3UCpUd7HO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "08a03cdb-fe40-41ac-c4f9-5198c2d452e0"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>site_url</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "      <th>title_without_stopwords</th>\n",
              "      <th>text_without_stopwords</th>\n",
              "      <th>hasImage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>author</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Barracuda Brigade</th>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>muslims busted they stole millions in govt ben...</td>\n",
              "      <td>print they should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>muslims busted stole millions govt benefits</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reasoning with facts</th>\n",
              "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
              "      <td>re why did attorney general loretta lynch plea...</td>\n",
              "      <td>why did attorney general loretta lynch plead t...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>attorney general loretta lynch plead fifth</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Barracuda Brigade</th>\n",
              "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
              "      <td>breaking weiner cooperating with fbi on hillar...</td>\n",
              "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fed Up</th>\n",
              "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
              "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
              "      <td>email kayla mueller was a prisoner and torture...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fed Up</th>\n",
              "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
              "      <td>fantastic trumps  point plan to reform healthc...</td>\n",
              "      <td>email healthcare reform to make america great ...</td>\n",
              "      <td>english</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
              "      <td>bias</td>\n",
              "      <td>Real</td>\n",
              "      <td>fantastic trumps point plan reform healthcare ...</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          published  ... hasImage\n",
              "author                                               ...         \n",
              "Barracuda Brigade     2016-10-26T21:41:00.000+03:00  ...      1.0\n",
              "reasoning with facts  2016-10-29T08:47:11.259+03:00  ...      1.0\n",
              "Barracuda Brigade     2016-10-31T01:41:49.479+02:00  ...      1.0\n",
              "Fed Up                2016-11-01T05:22:00.000+02:00  ...      1.0\n",
              "Fed Up                2016-11-01T21:56:00.000+02:00  ...      1.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnAp8w_nKesT"
      },
      "source": [
        "data['text_len'] = data['text'].apply(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAZ2XnvAeS_7"
      },
      "source": [
        "data['len_title'] = data['title'].apply(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NheRYAhPEgKq"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHpb492Zeuqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb6d950-243d-45b5-b286-fa2e48090463"
      },
      "source": [
        "# Plot article type distribution\n",
        "df_type = data['type'].value_counts()\n",
        "sns.barplot(np.arange(len(df_type)), df_type)\n",
        "plt.xticks(np.arange(len(df_type)), df_type.index.values.tolist(), rotation=90)\n",
        "plt.title('Article type count', fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3ef06109d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7f3eef5337d0>,\n",
              "  <matplotlib.axis.XTick at 0x7f3eef533790>,\n",
              "  <matplotlib.axis.XTick at 0x7f3eef5333d0>,\n",
              "  <matplotlib.axis.XTick at 0x7f3eef4a6910>,\n",
              "  <matplotlib.axis.XTick at 0x7f3eef4a69d0>,\n",
              "  <matplotlib.axis.XTick at 0x7f3eef4b6290>,\n",
              "  <matplotlib.axis.XTick at 0x7f3eef4b6790>,\n",
              "  <matplotlib.axis.XTick at 0x7f3eef4b6cd0>],\n",
              " [Text(0, 0, 'bs'),\n",
              "  Text(0, 0, 'conspiracy'),\n",
              "  Text(0, 0, 'bias'),\n",
              "  Text(0, 0, 'hate'),\n",
              "  Text(0, 0, 'satire'),\n",
              "  Text(0, 0, 'state'),\n",
              "  Text(0, 0, 'junksci'),\n",
              "  Text(0, 0, 'fake')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Article type count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KO8ZCE_e3Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d836ebcf-1ca5-4532-8331-8563e65be2f3"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stopwords.words('english')[0:10] # Show some stop words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU7SAO5Ze32x"
      },
      "source": [
        "def text_process(mess):\n",
        "    \"\"\"\n",
        "    Takes in a string of text, then performs the following:\n",
        "    1. Remove all punctuation\n",
        "    2. Remove all stopwords\n",
        "    3. Perform lemmatization\n",
        "    4. Returns a list of the cleaned text\n",
        "    \"\"\"\n",
        "    # Check characters to see if they are in punctuation\n",
        "    nopunc = [char for char in mess if char not in string.punctuation]\n",
        "\n",
        "    # Join the characters again to form the string.\n",
        "    nopunc = ''.join(nopunc)\n",
        "    \n",
        "    # Now just remove any stopwords\n",
        "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "    \n",
        "    lemma = nlp.WordNetLemmatizer()\n",
        "    nopunc = [ lemma.lemmatize(word) for word in nopunc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjU7Cq-cfFto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bb66b1-84ad-4eaa-b191-7cad7d8b36ed"
      },
      "source": [
        "data['title'].apply(text_process)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "author\n",
              "Barracuda Brigade       [muslims, busted, stole, millions, govt, benef...\n",
              "reasoning with facts    [attorney, general, loretta, lynch, plead, fifth]\n",
              "Barracuda Brigade       [breaking, weiner, cooperating, fbi, hillary, ...\n",
              "Fed Up                  [pin, drop, speech, father, daughter, kidnappe...\n",
              "Fed Up                  [fantastic, trumps, point, plan, reform, healt...\n",
              "                                              ...                        \n",
              "Matt Barber                           [never, trumpers, must, reconsider]\n",
              "Jane Chastain               [election, crossroads, socialism, capitalism]\n",
              "Michael Brown                                 [reasons, ill, vote, trump]\n",
              "Ann Coulter               [new, country, women, minorities, hit, hardest]\n",
              "Larry Elder                      [trump, vs, clinton, risk, vs, disaster]\n",
              "Name: title, Length: 2045, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYXjWgCBfJs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b5fb88-5c86-401b-aa8a-7522c89b9ee4"
      },
      "source": [
        "data['text'].head(5).apply(text_process)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "author\n",
              "Barracuda Brigade       [print, pay, back, money, plus, interest, enti...\n",
              "reasoning with facts    [attorney, general, loretta, lynch, plead, fif...\n",
              "Barracuda Brigade       [red, state, fox, news, sunday, reported, morn...\n",
              "Fed Up                  [email, kayla, mueller, prisoner, tortured, is...\n",
              "Fed Up                  [email, healthcare, reform, make, america, gre...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvsR2-AgfKoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850011fc-3385-43f0-befc-962abae3a899"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_transformer = CountVectorizer(analyzer=text_process).fit(data['text'])\n",
        "\n",
        "# Print total number of vocab words\n",
        "print(len(bow_transformer.vocabulary_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-6YiUSTfOtY"
      },
      "source": [
        "messages_bow = bow_transformer.transform(data['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM0SWYcxfSJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac33e5c-d3c5-4549-8fd6-11e640d22d57"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
        "\n",
        "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
        "print(messages_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2045, 47111)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jmZT6GnfV1p"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(data.label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "posdjO_YPVrX"
      },
      "source": [
        "Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxSppIvoNHaK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, label_train, label_test = train_test_split(data['text'], y, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTBI3RXRM50j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfe0210-0620-4e5b-864f-90b787e62e4c"
      },
      "source": [
        "print(len(X_train), len(X_test), len(X_train) + len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1636 409 2045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY9Kb8QBBbnT"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liK2nrbtIkVG"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detect_model = MultinomialNB().fit(messages_tfidf, data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS2XCeqxgAos"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUXWuTRvgKBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a972d005-b439-4167-f799-d51d586ba85a"
      },
      "source": [
        "pipeline.fit(X_train,label_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function text_process at 0x7f3eef489440>,\n",
              "                                 binary=False, decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rWqoKm_gO4U"
      },
      "source": [
        "predictions1 = pipeline.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rH65dXmgTsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93e36e1-fefb-4ecd-85bf-39d1f35a2a21"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(predictions1,label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.66      0.79       396\n",
            "           1       0.08      0.85      0.14        13\n",
            "\n",
            "    accuracy                           0.67       409\n",
            "   macro avg       0.53      0.75      0.47       409\n",
            "weighted avg       0.96      0.67      0.77       409\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iewDPWytgjc1"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tRvaglkgoSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a6edc6-eb53-4d2a-ff22-80516fc0cbac"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=50, criterion='entropy',random_state=0)\n",
        "classifier.fit(messages_tfidf, data['label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkOs7rkogr9G"
      },
      "source": [
        "pipeline_rf = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', RandomForestClassifier()),  # train on TF-IDF vectors w/ SVM\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXmV4DPWgxj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5d275b-0313-4a7a-bddf-fc4f08949470"
      },
      "source": [
        "pipeline_rf.fit(X_train,label_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function text_process at 0x7f3eef489440>,\n",
              "                                 binary=False, decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGVJcNcig0bF"
      },
      "source": [
        "predictions2 = pipeline_rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZe7HSF5g3kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d919a0-de8c-42d9-919e-50f26238e0b5"
      },
      "source": [
        "print(classification_report(predictions2,label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85       315\n",
            "           1       0.52      0.81      0.64        94\n",
            "\n",
            "    accuracy                           0.79       409\n",
            "   macro avg       0.73      0.79      0.74       409\n",
            "weighted avg       0.84      0.79      0.80       409\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYHD5WLVhUt0"
      },
      "source": [
        "DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COs-39mkhQCM"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42, criterion=\"entropy\",\n",
        "                             min_samples_split=10, min_samples_leaf=10, max_depth=3, max_leaf_nodes=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBjeHwOvhXiK"
      },
      "source": [
        "pipeline_dt = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', DecisionTreeClassifier()),  # train on TF-IDF vectors w/ SVM\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjYfWwSvhay4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d5296f-968c-4b86-cb4f-3c6ca5283932"
      },
      "source": [
        "pipeline_dt.fit(X_train,label_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function text_process at 0x7f3eef489440>,\n",
              "                                 binary=False, decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b...\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                        criterion='gini', max_depth=None,\n",
              "                                        max_features=None, max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        presort='deprecated', random_state=None,\n",
              "                                        splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekYTtAXwhdyK"
      },
      "source": [
        "predictions_dt = pipeline_dt.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPK70MLUhjWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0582c29-3290-4928-919c-1ca67efb67e0"
      },
      "source": [
        "print(classification_report(predictions_dt,label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.81       259\n",
            "           1       0.68      0.66      0.67       150\n",
            "\n",
            "    accuracy                           0.76       409\n",
            "   macro avg       0.74      0.74      0.74       409\n",
            "weighted avg       0.76      0.76      0.76       409\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5mkbD5bhm9c"
      },
      "source": [
        "Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9IEtKt0UchH"
      },
      "source": [
        "svm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBDw9ONBUd5e"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "svm=LinearSVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRLg1IsMUfV2"
      },
      "source": [
        "pipeline_svm = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', LinearSVC()),  # train on TF-IDF vectors w/ SVM\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L3z4jFoVC6H",
        "outputId": "eb358258-cd68-4fa4-e307-226701bbceca"
      },
      "source": [
        "pipeline_svm.fit(X_train,label_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function text_process at 0x7f3eef489440>,\n",
              "                                 binary=False, decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqYmWRaaVLnM"
      },
      "source": [
        "predictions_svm = pipeline_gbm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJhrwfHpVXOG",
        "outputId": "b76ef032-f872-48e5-86d1-f3651df69e19"
      },
      "source": [
        "print(classification_report(predictions_svm,label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.81      0.86       305\n",
            "           1       0.59      0.83      0.69       104\n",
            "\n",
            "    accuracy                           0.81       409\n",
            "   macro avg       0.76      0.82      0.78       409\n",
            "weighted avg       0.85      0.81      0.82       409\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}